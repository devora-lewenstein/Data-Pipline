{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pipeline import Pipeline, build_csv\n",
    "from stop_words import stop_words\n",
    "import string\n",
    "import json\n",
    "import io\n",
    "import datetime\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pipeline.task()\n",
    "def file_to_json():\n",
    "    with open('hn_stories_2014.json', \"r\") as f:\n",
    "        stories = json.load(f)\n",
    "      #  print(stories)- to see the file to know to pull out idx (eg.stories)\n",
    "        stories = stories['stories']\n",
    "    return stories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pipeline.task(depends_on = file_to_json)\n",
    "def filter_stories(stories):\n",
    "    filter_stories = []\n",
    "    for each in stories:\n",
    "        if each['points']>50 and each['num_comments']>1 and not each['title'].startswith('Ask HN'):\n",
    "            filter_stories.append(each)\n",
    "        else:\n",
    "            pass\n",
    "    return filter_stories       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(story)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pipeline.task(depends_on = filter_stories)\n",
    "def json_to_csv(stories):\n",
    "    lines = []\n",
    "    for each in stories:\n",
    "#         story = each['objectID'],  datetime.datetime.strptime(each['created_at'], '%Y-%m-%dT%H:%M:%SZ'), each['url'], each['points'], each['title']\n",
    "#         lines.append(story)\n",
    "#         set it as a tuple (double bracket) and put it in the append - that way you don't have a variable - more robust!!\n",
    "        lines.append((each['objectID'],  datetime.datetime.strptime(each['created_at'], '%Y-%m-%dT%H:%M:%SZ'), each['url'], each['points'], each['title']))\n",
    "    return build_csv(lines, ['objectID', 'created_at', 'url', 'points', 'title'], io.StringIO())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is a image of the generator not still working the generator\n",
    "#print(*csv, sep='\\n')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# %load pipeline.py\n",
    "#file - when use 'with open' it does an open so we can see it.  process transferring list of list json file into a csv.  to do a process of strucuture change need the T of ETL - transformation to the list of list to a csv.  The grabbing hold of this data needs a temporary storage to put it somewhere.  it need to grab on to the intial list of list to change it\n",
    "\n",
    "list file is where it is going to be during the grab\n",
    "\n",
    "\n",
    "def build_csv(lines, header=None, file=None):\n",
    "    if header:\n",
    "        lines = itertools.chain([header], lines)\n",
    "    writer = csv.writer(file, delimiter=',')\n",
    "    writer.writerows(lines)\n",
    "    file.seek(0)\n",
    "    return file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pipeline.task(depends_on = json_to_csv)\n",
    "\n",
    "def extract_titles(csv_file):\n",
    "    reader = csv.reader(csv_file)\n",
    "    header = next(reader)\n",
    "    idx = header.index('title')\n",
    "    return (row[idx] for row in reader)    \n",
    "\n",
    "#this is incorrect cause you are not using your generator on the for loop, need the for loop in the generatr\n",
    "#     uniques = []\n",
    "#     for line in reader:\n",
    "#         uniques.append(line['title'])\n",
    "#     yield (uniques)\n",
    "#title = extract_titles(csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pipeline.task(depends_on = extract_titles)\n",
    "def clean_titles(idx):\n",
    "    for each in idx:\n",
    "        yield each.lower().translate(str.maketrans('', '', string.punctuation + '–,“,—,”,’,‘,…,')).st\n",
    "\n",
    "# replace takes up a lot more memory\n",
    "#        yield each.lower().translate(str.maketrans('', '', string.punctuation)).replace('‘', '').replace('’', '').replace('–', ' ').replace('”', '').replace('“', '').replace('…', '').strip()\n",
    "\n",
    "        \n",
    "#        print(each.lower().translate(str.maketrans('', '', string.punctuation)).replace('‘', '').replace('’', '').replace('–', ' ').replace('”', '').replace('“', '').strip() )\n",
    "#        print (each.lower().replace('[{}]'.format(string.punctuation), '').replace('‘', '').replace('’', ''))\n",
    "\n",
    "#     using a yield hold on to each list and runs in again and again like appending it to a list but without bringing in the data\n",
    "#     list=[]\n",
    "#     for each in idx:\n",
    "#         list.append(each.lower().translate(str.maketrans('', '', string.punctuation)).replace('‘', '').replace('’', '').replace('–', ' ').replace('”', '').replace('“', '').replace('…', '').strip())\n",
    "\n",
    "#     return list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pipeline.task(depends_on = clean_titles)\n",
    "def build_keyword_dictionary(idx):\n",
    "    counts = {}\n",
    "    for row in idx:\n",
    "         for word in row.split():\n",
    "            if word not in stop_words:\n",
    "                if word not in counts:\n",
    "                    counts[word] = 0\n",
    "                counts[word] += 1\n",
    "    return sorted(counts.items(), key=lambda x: (-x[1], x[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pipeline.task(depends_on = build_keyword_dictionary)\n",
    "# def top_100(dictionary):\n",
    "#     dict1 = dictionary[:99]\n",
    "#     tup = tuple(dict1)\n",
    "#     return tup\n",
    "def top_100(dictionary):\n",
    "    return tuple(dictionary[:99])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('new', 185), ('google', 167), ('bitcoin', 101), ('open', 93), ('programming', 90), ('web', 89), ('data', 86), ('video', 79), ('python', 76), ('code', 72), ('facebook', 72), ('released', 71), ('using', 71), ('2013', 65), ('javascript', 65), ('free', 64), ('game', 64), ('source', 64), ('internet', 63), ('c', 59), ('linux', 59), ('microsoft', 59), ('app', 58), ('dont', 57), ('pdf', 55), ('language', 54), ('work', 54), ('2014', 52), ('software', 52), ('startup', 51), ('apple', 50), ('make', 50), ('use', 50), ('security', 48), ('time', 48), ('yc', 48), ('github', 45), ('nsa', 45), ('windows', 44), ('1', 41), ('heartbleed', 41), ('like', 41), ('way', 41), ('world', 41), ('computer', 40), ('project', 40), ('design', 37), ('git', 37), ('ios', 37), ('twitter', 37), ('users', 37), ('big', 36), ('ceo', 36), ('developer', 36), ('life', 36), ('os', 36), ('vs', 36), ('day', 35), ('android', 34), ('online', 34), ('simple', 34), ('court', 33), ('years', 33), ('api', 32), ('apps', 32), ('browser', 32), ('guide', 32), ('learning', 32), ('mt', 32), ('says', 32), ('amazon', 31), ('engine', 31), ('fast', 31), ('firefox', 31), ('gox', 31), ('mozilla', 31), ('problem', 31), ('server', 31), ('site', 31), ('introducing', 30), ('year', 30), ('better', 29), ('built', 29), ('million', 29), ('people', 29), ('stop', 29), ('support', 29), ('text', 29), ('3', 28), ('development', 28), ('does', 28), ('tech', 28), ('2048', 27), ('best', 27), ('billion', 27), ('chrome', 27), ('developers', 27), ('did', 27), ('inside', 27))\n"
     ]
    }
   ],
   "source": [
    "ran = pipeline.run()\n",
    "print(ran[top_100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
